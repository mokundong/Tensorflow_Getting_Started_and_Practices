{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Current loss: 0.511022\n",
      "Step: 1000 Current loss: 0.0989262\n",
      "Step: 2000 Current loss: 0.0847897\n",
      "Step: 3000 Current loss: 0.0765676\n",
      "Step: 4000 Current loss: 0.0713796\n",
      "Step: 5000 Current loss: 0.0681821\n",
      "Step: 6000 Current loss: 0.066096\n",
      "Step: 7000 Current loss: 0.0648208\n",
      "Step: 8000 Current loss: 0.0636919\n",
      "Step: 9000 Current loss: 0.0625575\n",
      "Step: 10000 Current loss: 0.0613905\n",
      "Step: 11000 Current loss: 0.060045\n",
      "Step: 12000 Current loss: 0.0586552\n",
      "Step: 13000 Current loss: 0.0572999\n",
      "Step: 14000 Current loss: 0.0560851\n",
      "Step: 15000 Current loss: 0.0549457\n",
      "Step: 16000 Current loss: 0.0539689\n",
      "Step: 17000 Current loss: 0.0530369\n",
      "Step: 18000 Current loss: 0.0520965\n",
      "Step: 19000 Current loss: 0.0512168\n",
      "loss:\n",
      " 0.107849\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.colors import colorConverter, ListedColormap \n",
    "# 对于上面的fit可以这么扩展变成动态的\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def onehot(y,start,end):\n",
    "    ohe = OneHotEncoder()\n",
    "    a = np.linspace(start,end-1,end-start)\n",
    "    b =np.reshape(a,[-1,1]).astype(np.int32)\n",
    "    ohe.fit(b)\n",
    "    c=ohe.transform(y).toarray()  \n",
    "    return c  \n",
    "    \n",
    "def generate(sample_size, num_classes, diff,regression=False):\n",
    "    np.random.seed(10)\n",
    "    mean = np.random.randn(2)\n",
    "    cov = np.eye(2)  \n",
    "    \n",
    "    #len(diff)\n",
    "    samples_per_class = int(sample_size/num_classes)\n",
    "\n",
    "    X0 = np.random.multivariate_normal(mean, cov, samples_per_class)\n",
    "    Y0 = np.zeros(samples_per_class)\n",
    "    \n",
    "    for ci, d in enumerate(diff):\n",
    "        X1 = np.random.multivariate_normal(mean+d, cov, samples_per_class)\n",
    "        Y1 = (ci+1)*np.ones(samples_per_class)\n",
    "    \n",
    "        X0 = np.concatenate((X0,X1))\n",
    "        Y0 = np.concatenate((Y0,Y1))\n",
    "\n",
    "  \n",
    "    if regression==False: #one-hot  0 into the vector \"1 0\n",
    "        Y0 = np.reshape(Y0,[-1,1])        \n",
    "        #print(Y0.astype(np.int32))\n",
    "        Y0 = onehot(Y0.astype(np.int32),0,num_classes)\n",
    "        #print(Y0)\n",
    "    X, Y = shuffle(X0, Y0)\n",
    "    #print(X, Y)\n",
    "    return X,Y   \n",
    "    \n",
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(10)\n",
    "input_dim = 2\n",
    "num_classes =4 \n",
    "X, Y = generate(320,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],True)\n",
    "Y=Y%2\n",
    "#colors = ['r' if l == 0.0 else 'b' for l in Y[:]]\n",
    "#plt.scatter(X[:,0], X[:,1], c=colors)\n",
    "xr=[]\n",
    "xb=[]\n",
    "for(l,k) in zip(Y[:],X[:]):\n",
    "    if l == 0.0 :\n",
    "        xr.append([k[0],k[1]])        \n",
    "    else:\n",
    "        xb.append([k[0],k[1]])\n",
    "xr =np.array(xr)\n",
    "xb =np.array(xb)      \n",
    "plt.scatter(xr[:,0], xr[:,1], c='r',marker='+')\n",
    "plt.scatter(xb[:,0], xb[:,1], c='b',marker='o')\n",
    "plt.show() \n",
    "\n",
    "Y=np.reshape(Y,[-1,1])\n",
    "\n",
    "learning_rate = 1e-4\n",
    "n_input  = 2\n",
    "n_label  = 1\n",
    "#n_hidden = 2#欠拟合\n",
    "n_hidden = 200\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_label])\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden], stddev=0.1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden, n_label], stddev=0.1))\n",
    "\t} \n",
    "biases = {\n",
    "    'h1': tf.Variable(tf.zeros([n_hidden])),\n",
    "    'h2': tf.Variable(tf.zeros([n_label]))\n",
    "    }    \n",
    "\n",
    "layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['h1']), biases['h1']))\n",
    "#y_pred = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['h2']),biases['h2']))\n",
    "#y_pred = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['h2']),biases['h2']))#局部最优解\n",
    "\n",
    "#y_pred = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['h2']),biases['h2']))\n",
    "\n",
    "#Leaky relus  40000次 ok\n",
    "layer2 =tf.add(tf.matmul(layer_1, weights['h2']),biases['h2'])\n",
    "y_pred = tf.maximum(layer2,0.01*layer2)\n",
    " \n",
    "loss=tf.reduce_mean((y_pred-y)**2)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#加载\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for i in range(20000):#  \n",
    "  \n",
    "  _, loss_val = sess.run([train_step, loss], feed_dict={x: X, y: Y})\n",
    "\n",
    "  if i % 1000 == 0:\n",
    "    print (\"Step:\", i, \"Current loss:\", loss_val)\n",
    "\n",
    "#colors = ['r' if l == 0.0 else 'b' for l in Y[:]]\n",
    "#plt.scatter(X[:,0], X[:,1], c=colors)\n",
    "xr=[]\n",
    "xb=[]\n",
    "for(l,k) in zip(Y[:],X[:]):\n",
    "    if l == 0.0 :\n",
    "        xr.append([k[0],k[1]])        \n",
    "    else:\n",
    "        xb.append([k[0],k[1]])\n",
    "xr =np.array(xr)\n",
    "xb =np.array(xb)      \n",
    "plt.scatter(xr[:,0], xr[:,1], c='r',marker='+')\n",
    "plt.scatter(xb[:,0], xb[:,1], c='b',marker='o')\n",
    "\n",
    "    \n",
    "nb_of_xs = 200\n",
    "xs1 = np.linspace(-3, 10, num=nb_of_xs)\n",
    "xs2 = np.linspace(-3, 10, num=nb_of_xs)\n",
    "xx, yy = np.meshgrid(xs1, xs2) # create the grid\n",
    "# Initialize and fill the classification plane\n",
    "classification_plane = np.zeros((nb_of_xs, nb_of_xs))\n",
    "for i in range(nb_of_xs):\n",
    "    for j in range(nb_of_xs):\n",
    "        #classification_plane[i,j] = nn_predict(xx[i,j], yy[i,j])\n",
    "        classification_plane[i,j] = sess.run(y_pred, feed_dict={x: [[ xx[i,j], yy[i,j] ]]} )\n",
    "        classification_plane[i,j] = int(classification_plane[i,j])\n",
    "\n",
    "# Create a color map to show the classification colors of each grid point\n",
    "cmap = ListedColormap([\n",
    "        colorConverter.to_rgba('r', alpha=0.30),\n",
    "        colorConverter.to_rgba('b', alpha=0.30)])\n",
    "# Plot the classification plane with decision boundary and input samples\n",
    "plt.contourf(xx, yy, classification_plane, cmap=cmap)\n",
    "plt.show() \n",
    "\n",
    "\n",
    "xTrain, yTrain = generate(12,num_classes,  [[3.0,0],[3.0,3.0],[0,3.0]],True)\n",
    "yTrain=yTrain%2\n",
    "#colors = ['r' if l == 0.0 else 'b' for l in yTrain[:]]\n",
    "#plt.scatter(xTrain[:,0], xTrain[:,1], c=colors)\n",
    "\n",
    "xr=[]\n",
    "xb=[]\n",
    "for(l,k) in zip(yTrain[:],xTrain[:]):\n",
    "    if l == 0.0 :\n",
    "        xr.append([k[0],k[1]])        \n",
    "    else:\n",
    "        xb.append([k[0],k[1]])\n",
    "xr =np.array(xr)\n",
    "xb =np.array(xb)      \n",
    "plt.scatter(xr[:,0], xr[:,1], c='r',marker='+')\n",
    "plt.scatter(xb[:,0], xb[:,1], c='b',marker='o')\n",
    "\n",
    "\n",
    "#plt.show() \n",
    "yTrain=np.reshape(yTrain,[-1,1])           \n",
    "print (\"loss:\\n\", sess.run(loss, feed_dict={x: xTrain, y: yTrain}))          \n",
    "\n",
    "nb_of_xs = 200\n",
    "xs1 = np.linspace(-1, 8, num=nb_of_xs)\n",
    "xs2 = np.linspace(-1, 8, num=nb_of_xs)\n",
    "xx, yy = np.meshgrid(xs1, xs2) # create the grid\n",
    "# Initialize and fill the classification plane\n",
    "classification_plane = np.zeros((nb_of_xs, nb_of_xs))\n",
    "for i in range(nb_of_xs):\n",
    "    for j in range(nb_of_xs):\n",
    "        #classification_plane[i,j] = nn_predict(xx[i,j], yy[i,j])\n",
    "        classification_plane[i,j] = sess.run(y_pred, feed_dict={x: [[ xx[i,j], yy[i,j] ]]} )\n",
    "        classification_plane[i,j] = int(classification_plane[i,j])\n",
    "\n",
    "# Create a color map to show the classification colors of each grid point\n",
    "cmap = ListedColormap([\n",
    "        colorConverter.to_rgba('r', alpha=0.30),\n",
    "        colorConverter.to_rgba('b', alpha=0.30)])\n",
    "# Plot the classification plane with decision boundary and input samples\n",
    "plt.contourf(xx, yy, classification_plane, cmap=cmap)\n",
    "plt.show()   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda]",
   "language": "python",
   "name": "conda-env-Anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
