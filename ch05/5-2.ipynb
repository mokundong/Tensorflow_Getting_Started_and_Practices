{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "#定义占位符\n",
    "x = tf.placeholder(tf.float32,[None,784]) #28*28=784\n",
    "y = tf.placeholder(tf.float32,[None,10]) #0~9,None表示输入任意数量的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义学习参数\n",
    "W = tf.Variable(tf.random_normal([784,10])) #权重\n",
    "b = tf.Variable(tf.zeros([10])) #偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义输出节点,正向传输\n",
    "pred = tf.nn.softmax(tf.matmul(x,W) + b) #pred = W*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义方向传播结构\n",
    "#损失函数\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))\n",
    "#学习率\n",
    "learning_rate = 0.01\n",
    "#优化器--这里使用梯度下降\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练、保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 8.976913220\n",
      "Epoch: 0002 cost= 4.733122895\n",
      "Epoch: 0003 cost= 3.255746334\n",
      "Epoch: 0004 cost= 2.553567848\n",
      "Epoch: 0005 cost= 2.142943900\n",
      "Epoch: 0006 cost= 1.874906544\n",
      "Epoch: 0007 cost= 1.687199714\n",
      "Epoch: 0008 cost= 1.548528033\n",
      "Epoch: 0009 cost= 1.441754161\n",
      "Epoch: 0010 cost= 1.356811014\n",
      "Epoch: 0011 cost= 1.287214426\n",
      "Epoch: 0012 cost= 1.228989819\n",
      "Epoch: 0013 cost= 1.179359489\n",
      "Epoch: 0014 cost= 1.136352248\n",
      "Epoch: 0015 cost= 1.098950819\n",
      "Epoch: 0016 cost= 1.065595591\n",
      "Epoch: 0017 cost= 1.035973967\n",
      "Epoch: 0018 cost= 1.009133914\n",
      "Epoch: 0019 cost= 0.984901657\n",
      "Epoch: 0020 cost= 0.962814927\n",
      "Epoch: 0021 cost= 0.942425323\n",
      "Epoch: 0022 cost= 0.923716131\n",
      "Epoch: 0023 cost= 0.906294772\n",
      "Epoch: 0024 cost= 0.890110382\n",
      "Epoch: 0025 cost= 0.875045527\n",
      "Epoch: 0026 cost= 0.860943490\n",
      "Epoch: 0027 cost= 0.847613270\n",
      "Epoch: 0028 cost= 0.835109133\n",
      "Epoch: 0029 cost= 0.823332681\n",
      "Epoch: 0030 cost= 0.812061847\n",
      "Epoch: 0031 cost= 0.801490700\n",
      "Epoch: 0032 cost= 0.791373967\n",
      "Epoch: 0033 cost= 0.781719713\n",
      "Epoch: 0034 cost= 0.772622341\n",
      "Epoch: 0035 cost= 0.763840480\n",
      "Epoch: 0036 cost= 0.755481459\n",
      "Epoch: 0037 cost= 0.747446238\n",
      "Epoch: 0038 cost= 0.739701575\n",
      "Epoch: 0039 cost= 0.732419751\n",
      "Epoch: 0040 cost= 0.725197171\n",
      "Epoch: 0041 cost= 0.718349929\n",
      "Epoch: 0042 cost= 0.711741140\n",
      "Epoch: 0043 cost= 0.705453856\n",
      "Epoch: 0044 cost= 0.699250498\n",
      "Epoch: 0045 cost= 0.693349812\n",
      "Epoch: 0046 cost= 0.687625575\n",
      "Epoch: 0047 cost= 0.682132852\n",
      "Epoch: 0048 cost= 0.676739863\n",
      "Epoch: 0049 cost= 0.671451945\n",
      "Epoch: 0050 cost= 0.666462225\n",
      "Epoch: 0051 cost= 0.661601915\n",
      "Epoch: 0052 cost= 0.656893285\n",
      "Epoch: 0053 cost= 0.652160951\n",
      "Epoch: 0054 cost= 0.647746950\n",
      "Epoch: 0055 cost= 0.643425125\n",
      "Epoch: 0056 cost= 0.639179547\n",
      "Epoch: 0057 cost= 0.635005279\n",
      "Epoch: 0058 cost= 0.631022290\n",
      "Epoch: 0059 cost= 0.627042501\n",
      "Epoch: 0060 cost= 0.623305870\n",
      "Epoch: 0061 cost= 0.619543259\n",
      "Epoch: 0062 cost= 0.615851815\n",
      "Epoch: 0063 cost= 0.612313075\n",
      "Epoch: 0064 cost= 0.608823083\n",
      "Epoch: 0065 cost= 0.605483525\n",
      "Epoch: 0066 cost= 0.602148893\n",
      "Epoch: 0067 cost= 0.598958484\n",
      "Epoch: 0068 cost= 0.595738293\n",
      "Epoch: 0069 cost= 0.592719504\n",
      "Epoch: 0070 cost= 0.589562533\n",
      "Epoch: 0071 cost= 0.586720651\n",
      "Epoch: 0072 cost= 0.583782876\n",
      "Epoch: 0073 cost= 0.580907128\n",
      "Epoch: 0074 cost= 0.578127405\n",
      "Epoch: 0075 cost= 0.575442371\n",
      "Epoch: 0076 cost= 0.572747539\n",
      "Epoch: 0077 cost= 0.570132152\n",
      "Epoch: 0078 cost= 0.567559175\n",
      "Epoch: 0079 cost= 0.564989391\n",
      "Epoch: 0080 cost= 0.562523436\n",
      "Epoch: 0081 cost= 0.560073303\n",
      "Epoch: 0082 cost= 0.557730169\n",
      "Epoch: 0083 cost= 0.555367157\n",
      "Epoch: 0084 cost= 0.553045576\n",
      "Epoch: 0085 cost= 0.550789310\n",
      "Epoch: 0086 cost= 0.548593386\n",
      "Epoch: 0087 cost= 0.546459000\n",
      "Epoch: 0088 cost= 0.544281960\n",
      "Epoch: 0089 cost= 0.542157601\n",
      "Epoch: 0090 cost= 0.540099318\n",
      "Epoch: 0091 cost= 0.537997757\n",
      "Epoch: 0092 cost= 0.536048406\n",
      "Epoch: 0093 cost= 0.534117309\n",
      "Epoch: 0094 cost= 0.532109001\n",
      "Epoch: 0095 cost= 0.530258240\n",
      "Epoch: 0096 cost= 0.528354117\n",
      "Epoch: 0097 cost= 0.526433679\n",
      "Epoch: 0098 cost= 0.524626272\n",
      "Epoch: 0099 cost= 0.522859569\n",
      "Epoch: 0100 cost= 0.521017475\n",
      "Epoch: 0101 cost= 0.519367303\n",
      "Epoch: 0102 cost= 0.517645071\n",
      "Epoch: 0103 cost= 0.515918774\n",
      "Epoch: 0104 cost= 0.514228221\n",
      "Epoch: 0105 cost= 0.512598366\n",
      "Epoch: 0106 cost= 0.510946392\n",
      "Epoch: 0107 cost= 0.509404298\n",
      "Epoch: 0108 cost= 0.507765404\n",
      "Epoch: 0109 cost= 0.506250443\n",
      "Epoch: 0110 cost= 0.504677518\n",
      "Epoch: 0111 cost= 0.503218958\n",
      "Epoch: 0112 cost= 0.501708551\n",
      "Epoch: 0113 cost= 0.500275189\n",
      "Epoch: 0114 cost= 0.498807966\n",
      "Epoch: 0115 cost= 0.497332534\n",
      "Epoch: 0116 cost= 0.495935951\n",
      "Epoch: 0117 cost= 0.494457270\n",
      "Epoch: 0118 cost= 0.493170824\n",
      "Epoch: 0119 cost= 0.491817247\n",
      "Epoch: 0120 cost= 0.490471463\n",
      "Epoch: 0121 cost= 0.489163900\n",
      "Epoch: 0122 cost= 0.487833564\n",
      "Epoch: 0123 cost= 0.486541094\n",
      "Epoch: 0124 cost= 0.485223240\n",
      "Epoch: 0125 cost= 0.483929074\n",
      "Epoch: 0126 cost= 0.482617504\n",
      "Epoch: 0127 cost= 0.481511188\n",
      "Epoch: 0128 cost= 0.480231628\n",
      "Epoch: 0129 cost= 0.478998558\n",
      "Epoch: 0130 cost= 0.477842287\n",
      "Epoch: 0131 cost= 0.476670258\n",
      "Epoch: 0132 cost= 0.475545349\n",
      "Epoch: 0133 cost= 0.474363106\n",
      "Epoch: 0134 cost= 0.473139008\n",
      "Epoch: 0135 cost= 0.472075101\n",
      "Epoch: 0136 cost= 0.470991662\n",
      "Epoch: 0137 cost= 0.469866841\n",
      "Epoch: 0138 cost= 0.468721330\n",
      "Epoch: 0139 cost= 0.467702637\n",
      "Epoch: 0140 cost= 0.466601782\n",
      "Epoch: 0141 cost= 0.465538548\n",
      "Epoch: 0142 cost= 0.464528324\n",
      "Epoch: 0143 cost= 0.463498893\n",
      "Epoch: 0144 cost= 0.462375132\n",
      "Epoch: 0145 cost= 0.461429107\n",
      "Epoch: 0146 cost= 0.460399424\n",
      "Epoch: 0147 cost= 0.459437101\n",
      "Epoch: 0148 cost= 0.458454871\n",
      "Epoch: 0149 cost= 0.457482901\n",
      "Epoch: 0150 cost= 0.456416007\n",
      "Epoch: 0151 cost= 0.455552170\n",
      "Epoch: 0152 cost= 0.454638476\n",
      "Epoch: 0153 cost= 0.453672135\n",
      "Epoch: 0154 cost= 0.452718214\n",
      "Epoch: 0155 cost= 0.451774934\n",
      "Epoch: 0156 cost= 0.450908688\n",
      "Epoch: 0157 cost= 0.449994205\n",
      "Epoch: 0158 cost= 0.449098951\n",
      "Epoch: 0159 cost= 0.448218928\n",
      "Epoch: 0160 cost= 0.447317365\n",
      "Epoch: 0161 cost= 0.446465355\n",
      "Epoch: 0162 cost= 0.445564184\n",
      "Epoch: 0163 cost= 0.444705257\n",
      "Epoch: 0164 cost= 0.443854859\n",
      "Epoch: 0165 cost= 0.443053269\n",
      "Epoch: 0166 cost= 0.442192884\n",
      "Epoch: 0167 cost= 0.441387369\n",
      "Epoch: 0168 cost= 0.440472124\n",
      "Epoch: 0169 cost= 0.439745375\n",
      "Epoch: 0170 cost= 0.438869574\n",
      "Epoch: 0171 cost= 0.438151078\n",
      "Epoch: 0172 cost= 0.437396034\n",
      "Epoch: 0173 cost= 0.436539674\n",
      "Epoch: 0174 cost= 0.435813781\n",
      "Epoch: 0175 cost= 0.435026967\n",
      "Epoch: 0176 cost= 0.434259939\n",
      "Epoch: 0177 cost= 0.433465711\n",
      "Epoch: 0178 cost= 0.432764046\n",
      "Epoch: 0179 cost= 0.432002849\n",
      "Epoch: 0180 cost= 0.431263658\n",
      "Epoch: 0181 cost= 0.430520918\n",
      "Epoch: 0182 cost= 0.429780641\n",
      "Epoch: 0183 cost= 0.429057085\n",
      "Epoch: 0184 cost= 0.428355918\n",
      "Epoch: 0185 cost= 0.427605032\n",
      "Epoch: 0186 cost= 0.426925892\n",
      "Epoch: 0187 cost= 0.426212949\n",
      "Epoch: 0188 cost= 0.425465099\n",
      "Epoch: 0189 cost= 0.424783802\n",
      "Epoch: 0190 cost= 0.424189902\n",
      "Epoch: 0191 cost= 0.423443929\n",
      "Epoch: 0192 cost= 0.422847980\n",
      "Epoch: 0193 cost= 0.422165441\n",
      "Epoch: 0194 cost= 0.421475907\n",
      "Epoch: 0195 cost= 0.420819938\n",
      "Epoch: 0196 cost= 0.420159137\n",
      "Epoch: 0197 cost= 0.419501535\n",
      "Epoch: 0198 cost= 0.418870974\n",
      "Epoch: 0199 cost= 0.418224696\n",
      "Epoch: 0200 cost= 0.417535353\n",
      "Finished!\n",
      "Accuracy: 0.8943\n",
      "Model saved in file: log/521model.ckpt\n",
      "Starting restore Model and the second Session...\n",
      "INFO:tensorflow:Restoring parameters from log/521model.ckpt\n",
      "Accuracy: 0.8943\n",
      "[3 0 7 9] [[  3.55847646e-03   5.10015696e-10   4.10430658e-08   9.90588069e-01\n",
      "    1.92073600e-07   5.61055122e-03   4.96279790e-06   1.34900972e-06\n",
      "    1.12011032e-04   1.24206330e-04]\n",
      " [  1.00000000e+00   3.40320696e-26   1.17690790e-09   2.01209492e-12\n",
      "    1.02993006e-16   5.81200474e-08   2.35429298e-09   7.65366977e-18\n",
      "    1.45602780e-10   1.32719687e-16]\n",
      " [  1.36619301e-11   9.70991069e-14   3.96313362e-06   1.71158299e-05\n",
      "    4.42085266e-08   1.42993430e-08   2.69615233e-12   9.99590933e-01\n",
      "    2.64516942e-08   3.88036133e-04]\n",
      " [  8.64524008e-11   1.65967174e-06   3.53072274e-08   1.42930541e-04\n",
      "    1.63201150e-02   3.54578788e-03   6.43850555e-08   7.22181940e-05\n",
      "    6.33097137e-04   9.79284048e-01]] [[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#迭代次数\n",
    "training_epochs = 200\n",
    "#batch_size 每次训练取的数据量\n",
    "batch_size = 100\n",
    "#中间状态打印间隔\n",
    "display_step = 1 \n",
    "\n",
    "#模型保存路径\n",
    "saver = tf.train.Saver()\n",
    "model_path = \"log/521model.ckpt\"\n",
    "\n",
    "#启动Session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) #Initializing OP\n",
    "    \n",
    "    #启动循环开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        #循环所有数据集\n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #运行优化器\n",
    "            _, c = sess.run([optimizer,cost],feed_dict={x:batch_xs,y:batch_ys})\n",
    "            #平均损失\n",
    "            avg_cost += c /total_batch\n",
    "        #显示信息\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\",'%04d' % (epoch+1),\"cost=\",\"{:.9f}\".format(avg_cost))\n",
    "    print(\"Finished!\")\n",
    "    \n",
    "    #测试模型\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    #计算精确率\n",
    "    accuracy = f=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print(\"Accuracy:\",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "    \n",
    "    #保存模型\n",
    "    save_path = saver.save(sess,model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "#测试模型    \n",
    "import pylab\n",
    "print (\"Starting restore Model and the second Session...\")\n",
    "with tf.Session() as sess:\n",
    "    #初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #恢复模型变量\n",
    "    saver.restore(sess,model_path)\n",
    "    \n",
    "    #测试模型\n",
    "    correct_predict = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    #计算精确度\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print(\"Accuracy:\",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "    \n",
    "    output = tf.argmax(pred,1)\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(4)\n",
    "    outputval,predv = sess.run([output,pred],feed_dict={x:batch_xs,y:batch_ys})\n",
    "    print(outputval,predv,batch_ys)\n",
    "    \n",
    "    im = batch_xs[0]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[1]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[2]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[3]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting restore Model and the second Session...\n",
      "INFO:tensorflow:Restoring parameters from log/521model.ckpt\n",
      "Accuracy: 0.8943\n",
      "[6 6 9 6] [[  3.24059979e-09   8.71780074e-17   1.35509854e-05   2.12521805e-08\n",
      "    2.51669633e-07   4.37270819e-06   9.99981761e-01   1.07654741e-09\n",
      "    5.09777323e-08   7.27295613e-10]\n",
      " [  3.24516217e-12   4.93763504e-13   2.05972086e-07   1.02106261e-10\n",
      "    8.45428616e-08   5.16235366e-09   9.99999762e-01   6.85560278e-14\n",
      "    4.43251587e-08   5.08301456e-10]\n",
      " [  1.08700033e-06   1.28877398e-09   6.50018865e-06   3.32755561e-04\n",
      "    1.17122683e-04   2.78560221e-02   2.33683204e-06   1.67513736e-06\n",
      "    1.87694021e-02   9.52913046e-01]\n",
      " [  1.73523929e-09   7.43960481e-05   1.52927334e-03   1.10765100e-02\n",
      "    4.67787868e-05   4.48837643e-04   9.64665413e-01   1.86740112e-09\n",
      "    2.09163893e-02   1.24238257e-03]] [[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import pylab\n",
    "print (\"Starting restore Model and the second Session...\")\n",
    "with tf.Session() as sess:\n",
    "    #初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #恢复模型变量\n",
    "    saver.restore(sess,model_path)\n",
    "    \n",
    "    #测试模型\n",
    "    correct_predict = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    #计算精确度\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print(\"Accuracy:\",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "    \n",
    "    output = tf.argmax(pred,1)\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(4)\n",
    "    outputval,predv = sess.run([output,pred],feed_dict={x:batch_xs,y:batch_ys})\n",
    "    print(outputval,predv,batch_ys)\n",
    "    \n",
    "    im = batch_xs[0]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[1]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[2]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[3]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
